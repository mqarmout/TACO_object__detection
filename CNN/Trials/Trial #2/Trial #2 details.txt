### **Key Changes in Trial 2**
1. **Model Architecture**:  
   - A **deeper model** was implemented in Trial 2:
     - Additional convolutional layers for richer feature extraction:
       - Added **256 and 512 filters** in deeper layers.
       - Used **MaxPooling layers** after each convolution block.
     - A denser fully connected layer with **512 units** was introduced.
     - Applied **Dropout of 0.3** for regularization.
   - Bounding box regression and classification were integrated into the model's output.

2. **Optimizer**:  
   - **Adam optimizer** with a learning rate of \(1 \times 10^{-3}\) was used.

### **Training Setup**
1. **Hyperparameters**:
   - **Epochs**: 100.
   - **Batch Size**: 64.
2. **Callbacks**:
   - **Evaluation Callback**:
     - Calculates Intersection over Union (IoU) and metrics like AP, Precision, and Recall.
   - **Loss Tracking Callback**: Monitors loss during training.

### Comparison of Results Between Trials (After Augmentation)

Both trials had the same **desired categories**:  
- `5: 0` ("Clear plastic bottle")  
- `12: 1` ("Drink can")  
- `36: 2` ("Plastic film").  


#### **Performance Metrics (After Augmentation)**

| **Metric**                | **Trial 1**                           | **Trial 2**                           |
|----------------------------|---------------------------------------|---------------------------------------|
| **Validation Loss**        | 1.9792                                | 1.9302                                |
| **Test Loss**              | 2.1047                                | 2.0812                                |
| **Mean IoU**               | 0.0519                                | 0.0525                                |
| **mAP (IoU 50-95)**        | 0.0168                                | 0.0171                                |
| **IoU Threshold: 0.50**    | AP: 0.0485, Precision: 0.1103, Recall: 0.1103 | AP: 0.0501, Precision: 0.1237, Recall: 0.1237 |
| **IoU Threshold: 0.75**    | AP: 0.0011, Precision: 0.0103, Recall: 0.0103 | AP: 0.0013, Precision: 0.0103, Recall: 0.0103 |
| **IoU Threshold: 0.90**    | AP: 0.0000, Precision: 0.0000, Recall: 0.0000 | AP: 0.0000, Precision: 0.0000, Recall: 0.0000 |

---

#### **Confusion Matrix (After Augmentation)**

| **Class**                 | **Trial 1 Accuracy, Precision, Recall**   | **Trial 2 Accuracy, Precision, Recall**   |
|---------------------------|-------------------------------------------|-------------------------------------------|
| **Class 0**               | Accuracy: 53.6082%, Precision: 42.1053%, Recall: 37.2881% | Accuracy: 53.6082%, Precision: 44.4444%, Recall: 40.6780% |
| **Class 1**               | Accuracy: 53.6082%, Precision: 52.1739%, Recall: 27.4509% | Accuracy: 53.6082%, Precision: 55.1724%, Recall: 31.3725% |
| **Class 2**               | Accuracy: 53.6082%, Precision: 54.1667%, Recall: 76.1905% | Accuracy: 53.6082%, Precision: 57.6577%, Recall: 76.1905% |

---

### **Key Changes and Observations**

1. **Validation Loss and Test Loss:** 
   - Trial 2 showed slightly better results, with lower validation and test losses (1.9302 vs. 1.9792 and 2.0812 vs. 2.1047).
   
2. **mAP@50-95 (Mean Average Precision):** 
   - Trial 2 slightly improved mAP (0.0171 vs. 0.0168), indicating better detection accuracy across all IoU thresholds.

3. **IoU Thresholds:**
   - **IoU 0.50**: Trial 2 had higher precision (0.1237 vs. 0.1103) and recall (0.1237 vs. 0.1103).
   - **IoU 0.75 and 0.90**: No major differences were observed, as both trials performed poorly at higher thresholds.

4. **Confusion Matrix:** 
   - Trial 2 consistently showed **better precision and recall** for all three classes, especially for Class 0 and Class 1, indicating improved detection accuracy for these categories.

---

### **Desired Improvements**
1. **Data Augmentation:** Explore additional augmentation techniques such as rotation, scaling, or color jittering to improve performance further.
2. **Model Adjustments:**
   - Increase model capacity with more convolutional layers or larger kernels.
   - Experiment with different optimizers (e.g., SGD with momentum).
   - Fine-tune the learning rate schedule.
3. **Class Imbalance:** Address potential class imbalance by oversampling underrepresented categories or using loss-weighting techniques.
4. **Higher IoU Thresholds:** Focus on improving AP for IoU thresholds of 0.75 and 0.90, as current results are negligible.